{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0715d15",
   "metadata": {},
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c246d9",
   "metadata": {},
   "source": [
    "# Projet robot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d776a07",
   "metadata": {},
   "source": [
    "IA705--Apprentissage pour la robotique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4709948",
   "metadata": {},
   "source": [
    "M.S. IA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ed7461",
   "metadata": {},
   "source": [
    "# Project summary and our contributions\n",
    "\n",
    "The objective of this project is not control the robot to imitate the humain behavoir par reinforcement learning. The humain behavoir is modeled as the body movement. In this project, the benchmark behavoir is recorded as a video file, and the movement trajectories of the related joints are extracted from the video. The idea of this project is to control the joints of a robot to follow the extracted movement trajectories. The main challenge of this project is as follows:\n",
    "* The number of robot (PoppY)joints is 13, each joint movement is modeled by an angle taking a continous value from -180 to 180 degrees. In general, we have infinitely many of possilities. Even we discritize the angle into 100 values, we have $100^{13}$ combinations. \n",
    "\n",
    "* The trajectory includes 286 points, which introduces exponentially more combinations.\n",
    "\n",
    "The above difficulties make the learning process impossible to converge.\n",
    "\n",
    "\n",
    "The contributions of our work is the propostions to alleviate the difficulties above.\n",
    "\n",
    "* In imitating the humain behavior, we use only two joints angles, namely the left and right $shoulder_x$. Because by observing the video, we find that the movement is mainly focusing on the shoulder joints in dimension $shoulder_x$. So we can do an approximation by considering only the left-right $shoulder_x$ parametres. To furtheur reduce the useless combinaision, the left $shoulder_x$ is limited in $[0, 180]$  degrees, and the right $shoulder_x$ is limited in $[-180, 0]$  degrees.\n",
    "* In the trajetory, we don't have to use all 286 points. According to the Shanon-Nyquist sampling theory, we can use only the key points. We use only 57 points by using a down sampling factor 1/5.\n",
    "* Even only left-right $shoulder_x$ parametres are considered, the combination between the two parametres is still a problem. By observing the video, it is true that only at most only one arm is moving. So we can fix one arm, and optimze the other arm, thus, the robot imitates the humain arms in a a sequential way. The combniantion is decoupled.\n",
    "* The policy we used is DDPG, which is suitable for continous problem\n",
    "* Some conclusions are drawn in the end of this notebook.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84075b6f",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7983a162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.path.exists(r'C:\\Users\\Moez\\Desktop\\MSIA\\poppy-torso-track\\gym-examples\\gym_examples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c47c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from utils.skeleton import *\n",
    "from utils.quaternion import *\n",
    "from utils.blazepose import blazepose_skeletons\n",
    "import os\n",
    "from pypot.creatures import PoppyTorso\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#from pypot.creatures.ik import IKChain\n",
    "from pypot.primitive.move import Move\n",
    "from pypot.primitive.move import MovePlayer\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Moez\\Desktop\\MSIA\\poppy-torso-track\\gym-examples')\n",
    "import gym_examples\n",
    "from gym.wrappers import FlattenObservation\n",
    "\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d23d71",
   "metadata": {},
   "source": [
    "## Make a environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "238796fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\ikpy\\chain.py:60: UserWarning: Link last_joint (index: 8) is of type 'fixed' but set as active in the active_links_mask. In practice, this fixed link doesn't provide any transformation so is as it were inactive\n",
      "  warnings.warn(\"Link {} (index: {}) is of type 'fixed' but set as active in the active_links_mask. In practice, this fixed link doesn't provide any transformation so is as it were inactive\".format(link.name, link_index))\n",
      "c:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len idx : 12, len skeletons: 279, idx [  0  25  50  75 100 125 150 175 200 225 250 275]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.35163873,  0.05685941,  0.0096534 , -0.10078628, -0.25616083,\n",
       "        0.01200609], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('gym_examples/Poppy-v0')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc1bc44",
   "metadata": {},
   "source": [
    "## Environment checking\n",
    "For the first time of making the environment, we can use the following code to check whether it is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4396003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3.common.env_checker import check_env\n",
    "# check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaebedd",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807993bc",
   "metadata": {},
   "source": [
    "We don't use all the points. For the down sampling factor of $1/5$, we take only [286/5]=57 points. The batch size is 57. we use just 15 epoches.\n",
    "\n",
    "We use a segmented reward function.\n",
    "* if  dis <=0.3:   reward = np.exp(-10*dis)\n",
    "* else:            reward = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cf6274",
   "metadata": {},
   "source": [
    "We choose a relatively bigger sigma in NormalActionNoise function: sigma=0.15\n",
    "\n",
    "\n",
    "DDPG is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1f61b4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "c:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 19 is out of bounds for dimension 0 with size 19",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m action_noise \u001b[38;5;241m=\u001b[39m NormalActionNoise(mean\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros(n_actions), sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.15\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mones(n_actions))\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m DDPG(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, action_noise\u001b[38;5;241m=\u001b[39maction_noise, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m57\u001b[39m )\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m57\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# save the log information\u001b[39;00m\n\u001b[0;32m      9\u001b[0m info \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(env\u001b[38;5;241m.\u001b[39minfos)\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\stable_baselines3\\ddpg\\ddpg.py:123\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDDPG,\n\u001b[0;32m    116\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDDPG:\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\stable_baselines3\\td3\\td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[0;32m    215\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTD3:\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:328\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_freq, TrainFreq)  \u001b[38;5;66;03m# check done in _setup_learn()\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 328\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rollout\u001b[38;5;241m.\u001b[39mcontinue_training:\n\u001b[0;32m    339\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:560\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[0;32m    557\u001b[0m actions, buffer_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    563\u001b[0m num_collected_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\shimmy\\openai_gym_compatibility.py:251\u001b[0m, in \u001b[0;36mGymV21CompatibilityV0.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: ActType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Any, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m        (observation, reward, terminated, truncated, info)\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgym_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender()\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\gym\\wrappers\\env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\MSIA\\poppy-torso-track\\gym-examples\\gym_examples\\envs\\Poppy_Env.py:98\u001b[0m, in \u001b[0;36mPoppyEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m         m\u001b[38;5;241m.\u001b[39mgoto_position(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, wait\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)             \n\u001b[0;32m     96\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_obs() \n\u001b[1;32m---> 98\u001b[0m dis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(obs \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_step\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mflatten())) \n\u001b[0;32m    100\u001b[0m reward \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m\u001b[38;5;241m*\u001b[39mdis)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 19 is out of bounds for dimension 0 with size 19"
     ]
    }
   ],
   "source": [
    "# The noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.15 * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1,batch_size = 57 )\n",
    "model.learn(total_timesteps= 57*15)\n",
    "\n",
    "# save the log information\n",
    "info = pd.DataFrame(env.infos)\n",
    "info.to_pickle('info.pkl')\n",
    "\n",
    "# save the model\n",
    "model.save(\"ddpg_imitation\")\n",
    "vec_env = model.get_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af18a6f",
   "metadata": {},
   "source": [
    "Read the log information and plot the reward curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46c8828a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'info.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minfo.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m t\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\pandas\\io\\pickle.py:179\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    178\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'info.pkl'"
     ]
    }
   ],
   "source": [
    "info = pd.read_pickle('info.pkl')\n",
    "t=[]\n",
    "for ep in info['episode'].unique():\n",
    "      t.append(info[info['episode']==ep]['reward'].mean())\n",
    "plt.plot(t)\n",
    "plt.xlabel(\"Number of epoches\")\n",
    "plt.ylabel(\"Average ewards\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11064308",
   "metadata": {},
   "source": [
    "# Test\n",
    "* For training, we can stop here. We can begin the test.\n",
    "* We can clear all the history data firstly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57619352",
   "metadata": {},
   "source": [
    "Because we cleared all the history data, we reload the resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7709305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from utils.skeleton import *\n",
    "from utils.quaternion import *\n",
    "from utils.blazepose import blazepose_skeletons\n",
    "import os\n",
    "from pypot.creatures import PoppyTorso\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#from pypot.creatures.ik import IKChain\n",
    "from pypot.primitive.move import Move\n",
    "from pypot.primitive.move import MovePlayer\n",
    "\n",
    "import sys\n",
    "sys.path.append('E:\\Anaconda\\envs\\gym-examples')\n",
    "import gym_examples\n",
    "from gym.wrappers import FlattenObservation\n",
    "\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c021167",
   "metadata": {},
   "source": [
    "Create the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19a25401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "VrepIOErrors",
     "evalue": "Remote error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mVrepIOErrors\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgym_examples/Poppy-v0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m env\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\gym\\envs\\registration.py:640\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[0;32m    637\u001b[0m     render_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 640\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43menv_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    643\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot an unexpected keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrender_mode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    644\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m apply_human_rendering\n\u001b[0;32m    645\u001b[0m     ):\n",
      "File \u001b[1;32m~\\Desktop\\MSIA\\poppy-torso-track\\gym-examples\\gym_examples\\envs\\Poppy_Env.py:31\u001b[0m, in \u001b[0;36mPoppyEnv.__init__\u001b[1;34m(self, goals, terminates)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpypot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vrep\n\u001b[0;32m     30\u001b[0m vrep\u001b[38;5;241m.\u001b[39mclose_all_connections()\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoppy \u001b[38;5;241m=\u001b[39m \u001b[43mPoppyTorso\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimulator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvrep\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#self.n_goals = goals\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\pypot\\creatures\\abstractcreature.py:103\u001b[0m, in \u001b[0;36mAbstractPoppyCreature.__new__\u001b[1;34m(cls, base_path, config, simulator, scene, host, port, id, shared_vrep_io, use_snap, snap_host, snap_port, snap_quiet, use_http, http_host, http_port, http_quiet, use_remote, remote_host, remote_port, use_ws, ws_host, ws_port, start_background_services, sync, **extra)\u001b[0m\n\u001b[0;32m    100\u001b[0m     host \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m127.0.0.1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 103\u001b[0m     poppy_creature \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_vrep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscene\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mscene\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeep-existing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_vrep_io\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshared_vrep_io\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m VrepConnectionError:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConnection to V-REP failed!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\pypot\\vrep\\__init__.py:104\u001b[0m, in \u001b[0;36mfrom_vrep\u001b[1;34m(config, vrep_host, vrep_port, scene, tracked_objects, tracked_collisions, id, shared_vrep_io)\u001b[0m\n\u001b[0;32m    100\u001b[0m motors \u001b[38;5;241m=\u001b[39m [motor_from_confignode(config, name)\n\u001b[0;32m    101\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmotors\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[0;32m    103\u001b[0m vc \u001b[38;5;241m=\u001b[39m VrepController(vrep_io, scene, motors, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m)\n\u001b[1;32m--> 104\u001b[0m \u001b[43mvc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_vrep_streaming\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m sensor_controllers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracked_objects:\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\pypot\\vrep\\controller.py:100\u001b[0m, in \u001b[0;36mVrepController._init_vrep_streaming\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mcall_remote_api(vrep_call,\n\u001b[0;32m     95\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mget_object_handle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_motor_name(m)),\n\u001b[0;32m     96\u001b[0m                                 streaming\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     97\u001b[0m                                 _force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Now actually retrieves all values\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m pos \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mget_motor_position(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_motor_name(m)) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmotors]\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Prepare streaming for setting position for each motor\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmotors, pos):\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\pypot\\vrep\\controller.py:100\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mcall_remote_api(vrep_call,\n\u001b[0;32m     95\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mget_object_handle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_motor_name(m)),\n\u001b[0;32m     96\u001b[0m                                 streaming\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     97\u001b[0m                                 _force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Now actually retrieves all values\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m pos \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_motor_position\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_motor_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmotors]\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Prepare streaming for setting position for each motor\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmotors, pos):\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\pypot\\vrep\\io.py:145\u001b[0m, in \u001b[0;36mVrepIO.get_motor_position\u001b[1;34m(self, motor_name)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_motor_position\u001b[39m(\u001b[38;5;28mself\u001b[39m, motor_name):\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Gets the motor current position. \"\"\"\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_remote_api\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msimxGetJointPosition\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmotor_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mstreaming\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\pypot\\vrep\\io.py:359\u001b[0m, in \u001b[0;36mVrepIO.call_remote_api\u001b[1;34m(self, func_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(err):\n\u001b[0;32m    357\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([vrep_error[\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m i]\n\u001b[0;32m    358\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m i, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(err) \u001b[38;5;28;01mif\u001b[39;00m e])\n\u001b[1;32m--> 359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m VrepIOErrors(msg)\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[1;31mVrepIOErrors\u001b[0m: Remote error"
     ]
    }
   ],
   "source": [
    "env = gym.make('gym_examples/Poppy-v0')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34814b3",
   "metadata": {},
   "source": [
    "Reload the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2949ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:95: UserWarning: You loaded a model that was trained using OpenAI Gym. We strongly recommend transitioning to Gymnasium by saving that model again.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 19 is out of bounds for dimension 0 with size 19",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     action, _states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs)\n\u001b[1;32m----> 7\u001b[0m     obs, rewards, dones, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     k  \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m286\u001b[39m :\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Moez\\anaconda3\\envs\\Robotics\\lib\\site-packages\\gym\\wrappers\\env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\MSIA\\poppy-torso-track\\gym-examples\\gym_examples\\envs\\Poppy_Env.py:98\u001b[0m, in \u001b[0;36mPoppyEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m         m\u001b[38;5;241m.\u001b[39mgoto_position(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, wait\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)             \n\u001b[0;32m     96\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_obs() \n\u001b[1;32m---> 98\u001b[0m dis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(obs \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_step\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mflatten())) \n\u001b[0;32m    100\u001b[0m reward \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m\u001b[38;5;241m*\u001b[39mdis)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 19 is out of bounds for dimension 0 with size 19"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = DDPG.load(\"ddpg_imitation\")\n",
    "\n",
    "obs = env.reset()\n",
    "k =0\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    k  += 5\n",
    "    \n",
    "    if k >= 286 :\n",
    "        break   #  test only one round\n",
    "        obs = env.reset()\n",
    "        k = 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ff231",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c9da2",
   "metadata": {},
   "source": [
    "Based on this projet, the robot successfully imitates the humain behavior. Because of the time reasons, there are still some work to improve.\n",
    "* The movement of the robot is not so smooth, because we used only 57 trajectory points. So we can try more points and higher sampling frequency for a smooth robot movement.\n",
    "* In the project, we considered only left-right $shoulder_x$ parametres.We used two dimensional action space. Actually, the arms are treated in sequential way, we can model this processing by using only 1-dimensional action space without losing the performance.\n",
    "* The overfitting point is not so easily determined. In our project, we found that the reward begun to rebound at 17th epoch. Actually, this point is not the best point to stop. We choose an even early point to stop at 15th epoch.\n",
    "\n",
    "This project is really a gainful and painful learning process. By this project, we have learned the following techniques:\n",
    "* How to build a gym environment for robot reinforcement learning.\n",
    "* How to analyse and decompose a complexe problem\n",
    "* How to set the reward.\n",
    "* Understanding the relationship between reward and the robot learning behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55e9040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
